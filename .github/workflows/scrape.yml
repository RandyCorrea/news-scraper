name: Scrape News

on:
  schedule:
    - cron: '0 */6 * * *' # Every 6 hours
  repository_dispatch:
    types: [trigger-scraper]
  workflow_dispatch:
    inputs:
      reason:
        description: 'Trigger reason'
        default: 'Manual'

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Scraper (w/ ML)
        run: |
          python scraper.py

      - name: Commit and Push
        run: |
          git config user.name "Bot Scraper"
          git config user.email "bot@news.local"
          # Add all changed data: news, model, etc.
          git add data/news.json data/model.pkl data/telegraph_token.json || true
          git commit -m "Auto: Update news, model & tokens [skip ci]" || exit 0
          git push

